--- a/llvm/tools/polly/lib/Analysis/Dependences.cpp	2015-10-07 20:37:00.000000000 +0400
+++ b/llvm/tools/polly/lib/Analysis/Dependences.cpp	2015-10-07 20:38:24.000000000 +0400
@@ -30,6 +30,10 @@
 #include "llvm/Support/Debug.h"
 #include "llvm/Support/CommandLine.h"
 
+#define CLOOG_INT_GMP 1
+#include "cloog/cloog.h"
+#include "cloog/isl/cloog.h"
+
 #include <isl/aff.h>
 #include <isl/flow.h>
 #include <isl/map.h>
@@ -217,6 +221,13 @@
   return IsParallel;
 }
 
+bool Dependences::isParallelFor(const clast_for *f) {
+  isl_set *Domain = isl_set_from_cloog_domain(f->domain);
+  assert(Domain && "Cannot access domain of loop");
+
+  return isParallelDimension(isl_set_copy(Domain), isl_set_n_dim(Domain));
+}
+
 void Dependences::printScop(raw_ostream &OS) const {
 }
 
--- a/llvm/tools/polly/include/polly/Dependences.h	2015-10-07 20:43:27.000000000 +0400
+++ b/llvm/tools/polly/include/polly/Dependences.h	2015-10-07 20:43:07.000000000 +0400
@@ -84,6 +84,16 @@
     bool isParallelDimension(__isl_take isl_set *LoopDomain,
                              unsigned ParallelDimension);
 
+    /// @brief Check if a loop is parallel
+    ///
+    /// Detect if a clast_for loop can be executed in parallel.
+    ///
+    /// @param f The clast for loop to check.
+    ///
+    /// @return bool Returns true if the incoming clast_for statement can
+    ///              execute in parallel.
+    bool isParallelFor(const clast_for *For);
+
     /// @brief Get the dependences in this Scop.
     ///
     /// @param Kinds This integer defines the different kinds of dependences
--- a/llvm/tools/polly/lib/Analysis/ScopInfo.cpp	(revision 156703)
+++ b/llvm/tools/polly/lib/Analysis/ScopInfo.cpp	(working copy)
@@ -239,7 +239,10 @@
 //===----------------------------------------------------------------------===//
 
 MemoryAccess::~MemoryAccess() {
-  isl_map_free(AccessRelation);
+  if(pollyAccessRelation)
+	  isl_map_free(pollyAccessRelation);
+  if(generalAccessRelation)
+	  isl_map_free(generalAccessRelation);
   isl_map_free(newAccessRelation);
 }
 
@@ -269,11 +272,42 @@
 }
 
 isl_map *MemoryAccess::getAccessRelation() const {
-  return isl_map_copy(AccessRelation);
+  return  (currentRelationType==RelationType_polly)?
+              isl_map_copy(pollyAccessRelation):isl_map_copy(generalAccessRelation);
 }
 
+void  MemoryAccess::setCurrentRelationType(MemoryAccess::RelationType relationType)
+{
+	if(relationType == RelationType_polly)
+	   assert(pollyAccessRelation && "set pollyAccessRelation before setCurrentRelationType");
+    else
+	   assert(generalAccessRelation && "set generalAccessRelation before setCurrentRelationType");
+	currentRelationType = relationType;
+}
+
+MemoryAccess::RelationType MemoryAccess::getCurrentRelationType()
+{
+	return currentRelationType;
+}
+
+void MemoryAccess::setGeneralAccessRelation(isl_map *accessRelation)
+{
+	if(generalAccessRelation)
+    	isl_map_free(generalAccessRelation);
+	generalAccessRelation = isl_map_copy(accessRelation);
+}
+
+void MemoryAccess::setPollyAccessRelation(isl_map *accessRelation)
+{
+	if(pollyAccessRelation)
+    	isl_map_free(pollyAccessRelation);
+	pollyAccessRelation = isl_map_copy(accessRelation);
+}
+
 std::string MemoryAccess::getAccessRelationStr() const {
-  return stringFromIslObj(AccessRelation);
+  isl_map *relation =  (currentRelationType==RelationType_polly)?
+             pollyAccessRelation:generalAccessRelation;
+	return stringFromIslObj(relation);
 }
 
 isl_map *MemoryAccess::getNewAccessRelation() const {
@@ -291,7 +325,8 @@
   return isl_basic_map_universe(Space);
 }
 
-MemoryAccess::MemoryAccess(const IRAccess &Access, ScopStmt *Statement) {
+MemoryAccess::MemoryAccess(const IRAccess &Access, ScopStmt *Statement)
+:generalAccessRelation(NULL),currentRelationType(RelationType_polly) {
   newAccessRelation = NULL;
   Type = Access.isRead() ? Read : Write;
   statement = Statement;
@@ -300,7 +335,7 @@
 
   if (!Access.isAffine()) {
     Type = (Type == Read) ? Read : MayWrite;
-    AccessRelation = isl_map_from_basic_map(createBasicAccessMap(Statement));
+    pollyAccessRelation = isl_map_from_basic_map(createBasicAccessMap(Statement));
     return;
   }
 
@@ -318,31 +353,36 @@
   isl_int v;
   isl_int_init(v);
   isl_int_set_si(v, Access.getElemSizeInBytes());
+  elemTypeSize = Access.getElemSizeInBytes();
   Affine = isl_pw_aff_scale_down(Affine, v);
   isl_int_clear(v);
 
-  AccessRelation = isl_map_from_pw_aff(Affine);
-  AccessRelation = isl_map_set_tuple_name(AccessRelation, isl_dim_in,
+  pollyAccessRelation = isl_map_from_pw_aff(Affine);
+  pollyAccessRelation = isl_map_set_tuple_name(pollyAccessRelation, isl_dim_in,
                                           Statement->getBaseName());
-  AccessRelation = isl_map_set_tuple_name(AccessRelation, isl_dim_out,
+  pollyAccessRelation = isl_map_set_tuple_name(pollyAccessRelation, isl_dim_out,
                                           getBaseName().c_str());
 }
 
 void MemoryAccess::realignParams() {
+  assert(currentRelationType == RelationType_polly && "for safety");
   isl_space *ParamSpace = statement->getParent()->getParamSpace();
-  AccessRelation = isl_map_align_params(AccessRelation, ParamSpace);
+  pollyAccessRelation = isl_map_align_params(pollyAccessRelation, ParamSpace);
+  if(generalAccessRelation)
+  generalAccessRelation = isl_map_align_params(generalAccessRelation, ParamSpace);
 }
 
-MemoryAccess::MemoryAccess(const Value *BaseAddress, ScopStmt *Statement) {
+MemoryAccess::MemoryAccess(const Value *BaseAddress, ScopStmt *Statement)
+:generalAccessRelation(NULL), currentRelationType(RelationType_polly) {
   newAccessRelation = NULL;
   BaseAddr = BaseAddress;
   Type = Read;
   statement = Statement;
 
   isl_basic_map *BasicAccessMap = createBasicAccessMap(Statement);
-  AccessRelation = isl_map_from_basic_map(BasicAccessMap);
+  pollyAccessRelation = isl_map_from_basic_map(BasicAccessMap);
   isl_space *ParamSpace = Statement->getParent()->getParamSpace();
-  AccessRelation = isl_map_align_params(AccessRelation, ParamSpace);
+  pollyAccessRelation = isl_map_align_params(pollyAccessRelation, ParamSpace);
 }
 
 void MemoryAccess::print(raw_ostream &OS) const {
@@ -367,6 +407,7 @@
 //     : i0 = o0, i1 = o1, ..., i(X-1) = o(X-1), iX < oX
 //
 static isl_map *getEqualAndLarger(isl_space *setDomain) {
+   
   isl_space *Space = isl_space_map_from_set(setDomain);
   isl_map *Map = isl_map_universe(isl_space_copy(Space));
   isl_local_space *MapLocalSpace = isl_local_space_from_space(Space);
@@ -402,6 +443,7 @@
 }
 
 isl_set *MemoryAccess::getStride(__isl_take const isl_set *domainSubset) const {
+
   isl_map *accessRelation = getAccessRelation();
   isl_set *scatteringDomain = const_cast<isl_set*>(domainSubset);
   isl_map *scattering = getStatement()->getScattering();
@@ -447,10 +489,12 @@
 }
 
 bool MemoryAccess::isStrideZero(const isl_set *DomainSubset) const {
+  assert(currentRelationType == RelationType_polly && "for safety");
   return isStrideX(DomainSubset, 0);
 }
 
 bool MemoryAccess::isStrideOne(const isl_set *DomainSubset) const {
+  assert(currentRelationType == RelationType_polly && "for safety");
   return isStrideX(DomainSubset, 1);
 }
 
--- a/llvm/tools/polly/lib/Analysis/ScopDetection.cpp	(revision 156703)
+++ b/llvm/tools/polly/lib/Analysis/ScopDetection.cpp	(working copy)
@@ -74,7 +74,7 @@
              cl::value_desc("The function name to detect scops in"),
              cl::ValueRequired, cl::init(""));
 
-static cl::opt<bool>
+cl::opt<bool>
 IgnoreAliasing("polly-ignore-aliasing",
                cl::desc("Ignore possible aliasing of the array bases"),
                cl::Hidden, cl::init(false));
--- a/llvm/tools/polly/lib/CodeGen/CodeGeneration.cpp	(revision 156703)
+++ b/llvm/tools/polly/lib/CodeGen/CodeGeneration.cpp	(working copy)
@@ -42,6 +42,7 @@
 #include "llvm/Support/Debug.h"
 #include "llvm/Target/TargetData.h"
 #include "llvm/Transforms/Utils/BasicBlockUtils.h"
+#include "llvm/Analysis/Verifier.h"
 
 #define CLOOG_INT_GMP 1
 #include "cloog/cloog.h"
@@ -51,9 +52,11 @@
 
 #include <vector>
 #include <utility>
+#include <string>
 
 using namespace polly;
 using namespace llvm;
+using namespace std;
 
 struct isl_set;
 
@@ -71,6 +74,20 @@
        cl::value_desc("OpenMP code generation enabled if true"),
        cl::init(false), cl::ZeroOrMore);
 
+cl::opt<bool>
+CUDA("enable-polly-CUDA",
+     cl::desc("Enable polly CUDA code generation"), cl::Hidden,
+     cl::value_desc("CUDA code generation enabled if true"),
+     cl::init(false));
+
+// CudaFunctions are extern functions defining thread position in grid.
+// Will be filled in CodeGeneration::addCUDADefinitions.
+std::vector<const char*> CudaFunctions;
+DenseMap<const char*,const char *> CudaInricics;
+
+// Dimensions contains the names of dimensions. Default are x, y, z.
+std::vector<string> dimensions;
+
 typedef DenseMap<const char*, Value*> CharMapT;
 
 /// Class to generate LLVM-IR that calculates the value of a clast_expr.
@@ -160,7 +177,60 @@
 
   llvm_unreachable("Unknown clast binary expression type");
 }
+						 
+static Value *createLoopForCUDA(IRBuilder<> *Builder, Value *LB, Value *UB,
+  Value *ThreadLB, Value *ThreadUB, Value *ThreadStride,
+  const char * dimension, Pass *P, BasicBlock **AfterBlock) {
+  Function *F = Builder->GetInsertBlock()->getParent();
+  LLVMContext &Context = F->getContext();
 
+  BasicBlock *PreheaderBB = Builder->GetInsertBlock();
+  BasicBlock *HeaderBB = BasicBlock::Create(Context, (string)"CUDA.LoopHeader." + dimension, F);
+  BasicBlock *BodyBB = BasicBlock::Create(Context, (string)"CUDA.LoopBody." + dimension, F);
+
+  BasicBlock *AfterBB = SplitBlock(PreheaderBB, Builder->GetInsertPoint()++, P);
+  AfterBB->setName((string)"CUDA.AfterLoop." + dimension);
+
+  PreheaderBB->getTerminator()->setSuccessor(0, HeaderBB);
+  DominatorTree &DT = P->getAnalysis<DominatorTree>();
+  DT.addNewBlock(HeaderBB, PreheaderBB);
+  Builder->SetInsertPoint(HeaderBB);
+
+  // Use the type of upper and lower bound.
+  assert(LB->getType() == UB->getType()
+    && "Different types for upper and lower bound.");
+
+  IntegerType *LoopIVType = dyn_cast<IntegerType>(UB->getType());
+  assert(LoopIVType && "UB is not integer?");
+
+  // IV
+  PHINode *IV = Builder->CreatePHI(LoopIVType, 2, (string)"CUDA.loopiv." + dimension);
+  IV->addIncoming(ThreadLB, PreheaderBB);
+
+  // IV increment.
+  Value *StrideValue = ThreadStride;
+  Value *IncrementedIV = Builder->CreateAdd(IV, StrideValue, (string)"CUDA.next_loopiv." + dimension);
+
+  // Exit condition.
+  // Maybe not executed at all.
+  // next iteration performed if loop condition is true:
+  // InductionVariable <= ThreadUpperBound && InductionVariable <= LoopUpperBound
+  Value *ExitCond = Builder->CreateICmpSLE(IV, ThreadUB, (string)"isInThreadBounds." + dimension); 
+
+  Builder->CreateCondBr(ExitCond, BodyBB, AfterBB);
+  DT.addNewBlock(BodyBB, HeaderBB);
+
+  Builder->SetInsertPoint(BodyBB);
+  Builder->CreateBr(HeaderBB);
+  IV->addIncoming(IncrementedIV, BodyBB);
+  DT.changeImmediateDominator(AfterBB, HeaderBB);
+
+  Builder->SetInsertPoint(BodyBB->begin());
+  *AfterBlock = AfterBB;
+
+  return IV;
+}
+
 Value *ClastExpCodeGen::codegen(const clast_reduction *r, Type *Ty) {
   assert((   r->type == clast_red_min
              || r->type == clast_red_max
@@ -215,6 +285,24 @@
 public:
   const std::vector<std::string> &getParallelLoops();
 
+  // Each thread has it's own position in Grid
+  // That position is computed in runtime for each dimension of grid
+  vector<Value*> BlockPositionInGrid;
+  vector<Value*> ThreadPositionInBlock;
+
+  // For each dimension of grid computes it's size (count of threads)
+  // GridSize contains respectively Value*
+  vector<Value*> GridSize;
+
+  // For each dimension of block it's size obtained by call to one of the CUDA Functions
+  // BlockSize contains respectively Value*
+  vector<Value*> BlockSize;
+
+  int goodNestedParallelLoopsCount;
+
+  // Maximal count of good nested parallel loops, which can be parallelized
+  int MaxDimensionsCount;
+
 private:
   // The Scop we code generate.
   Scop *S;
@@ -371,6 +371,219 @@
   /// statement.
   void codegenForOpenMP(const clast_for *f);
 
+  void createCUDAGridParamsAndPosInGridBlocks() {
+    Module *M = Builder.GetInsertBlock()->getParent()->getParent();
+    vector<Value *> GridParameters;
+
+    // GridParams BasicBlock - load Grid parameters by calling CUDA functions
+    BasicBlock *GridParamsBB = Builder.GetInsertBlock();
+    GridParamsBB->setName("CUDA.getGridParams");
+
+    // PosInGrid BasicBlock - compute thread positin in grid
+    BasicBlock *PosInGridBB=SplitBlock(GridParamsBB,GridParamsBB->getTerminator(),P);
+    PosInGridBB->setName("CUDA.getPositionInGrid");
+
+    // Compute needed values separately for each dimension.
+    for(int dimension = 0; dimension < goodNestedParallelLoopsCount; dimension++) {
+      Builder.SetInsertPoint(GridParamsBB->getTerminator());
+
+      // Call CUDA functions and store values in vector GridParameters.
+      for(int GridParameter = 0; GridParameter < 4; GridParameter ++) {
+        GridParameters.push_back(Builder.CreateCall(
+          M->getFunction(CudaFunctions[dimension * 4 + GridParameter]),
+            CudaInricics[CudaFunctions[dimension * 4 + GridParameter]] ));
+      }
+
+      Builder.SetInsertPoint(PosInGridBB->getTerminator());
+
+      // Grid Parameters for current dimension
+      Value *threadId = GridParameters[dimension * 4 + 0];
+      Value *blockId = GridParameters[dimension * 4 + 1];
+      Value *blockDim = GridParameters[dimension * 4 + 2];
+      Value *gridDim =  GridParameters[dimension * 4 + 3];
+
+      // Absolute position of block's first thread (position of block)
+      // blockId.x * blockDim.x - "position of block's thread 0 for dimension x"
+      Value* Position = Builder.CreateMul(blockId, blockDim,
+        string("PositionOfBlockInGrid.") + dimensions[dimension]);
+
+      // GridDim.x * blockDim.x - size of grid in threads for dimension x
+      Value * Size = Builder.CreateMul(gridDim, blockDim,
+        string("GridSize.") + dimensions[dimension]);
+
+      // Store values.
+      BlockPositionInGrid.push_back(Position);
+      ThreadPositionInBlock.push_back(threadId);
+      GridSize.push_back(Size);
+      BlockSize.push_back(blockDim);
+    }
+
+    BasicBlock *LoopPreheader=SplitBlock(PosInGridBB,PosInGridBB->getTerminator(),P);
+    Builder.SetInsertPoint(LoopPreheader->getTerminator());
+  }
+  
+  void codegenForCUDA(const clast_for *f) {
+    // At this point GridParamsBB and PosInGridBB BasicBlocks are already created.
+    // The needed Value*-es are stored in positionInGrid, GridSize, BlockSize for each thread.
+    int dimension = goodNestedParallelLoopsCount - parallelLoops.size();
+    const char * dimensionName = dimensions[dimension].c_str();
+
+    // In CountBoundsBB BasicBlock for each dimension compute:
+    //   CountOfIterations
+    //   ThreadUpperBound
+    //   ThreadLowerBound
+    //   Stride
+    // These values are different between threads in runtime.
+    BasicBlock * CountBoundsBB = Builder.GetInsertBlock();
+    CountBoundsBB->setName(string("CUDA.CountBounds.") + dimensionName);
+
+    IntegerType * IntType = Type::getInt32Ty(Builder.getContext());
+
+    // Lower and Upper Bounds of Loop
+    Value *lowerBound = ExpGen.codegen(f->LB,IntType);
+    Value *upperBound = ExpGen.codegen(f->UB,IntType);
+
+    // Stride of loop
+    assert(polly::APInt_from_MPZ(f->stride) != 0 && "what we must do in those situation?");
+    assert(polly::APInt_from_MPZ(f->stride).getSExtValue() > 0 && "TODO: support of negative stride");
+
+    Value *LoopStride = ConstantInt::get(IntType,
+      polly::APInt_from_MPZ(f->stride).zext(IntType->getBitWidth()));
+
+    // The number of loop's iterations.
+    // ((UpperBound - LowerBound) / stride + 1)
+    // The number of iterations minus one = (UpperBound - LowerBound) / stride
+    Value *UpperMinusLower = Builder.CreateSub(upperBound,lowerBound,
+      string("UB.minus.LB.") + dimensionName);
+    Value *NumOfIterationsMinusOne = Builder.CreateSDiv(UpperMinusLower,LoopStride,
+      string("NumOfIterationsMinusOne.") + dimensionName);
+
+    // Compute number of Iterations per thread.
+    // ((NumberOfIterations - 1) / GridSize) + 1)
+    // ( NumOfIterationsMinusOne / GridSize + 1)
+    Value *One = ConstantInt::get(lowerBound->getType(), 1);
+    Value *IterationsPerThreadMinusOne = Builder.CreateSDiv(
+      NumOfIterationsMinusOne, GridSize[dimension],
+      string("IterationsPerThreadMinusOne.") + dimensionName);
+    Value *IterationsPerThread = Builder.CreateAdd(
+      IterationsPerThreadMinusOne, One,
+      string("IterationsPerThread.") + dimensionName);
+
+    // Compute Thread's Upper and Lower Bounds and Stride
+    // ThreadLowerBound = LoopStride * (IterationsPerThread * BlockPosition + ThreadPositionInBlock)
+    // ThreadUpperBound = ThreadLowerBound + ThreadStride * (IterationsPerThread - 1)
+    // Stride = BlockSize (to increase probability of coalescing transactions to memory)
+    Value *BlockLowerBound = Builder.CreateMul(
+      BlockPositionInGrid[dimension], IterationsPerThread,
+      string("BlockLowerBound.") + dimensionName);
+    Value *BlockLBAddThreadPosInBlock = Builder.CreateAdd(
+      BlockLowerBound, ThreadPositionInBlock[dimension],
+      string("BlockLB.Add.ThreadPosInBlock.") + dimensionName);
+    Value *ThreadLowerBound = Builder.CreateMul(
+      BlockLBAddThreadPosInBlock, LoopStride,
+      string("ThreadLowerBound.") + dimensionName);
+    Value *ThreadStride = Builder.CreateMul(
+      LoopStride, BlockSize[dimension],
+      string("ThreadStride.") + dimensionName);
+    Value *StrideMulIterPerThreadMinusOne = Builder.CreateMul(
+      IterationsPerThreadMinusOne, ThreadStride,
+      string("ThreadStride.Mul.IterPerThreadMinusOne.") + dimensionName);
+    Value *ThreadUpperBound = Builder.CreateAdd(
+      ThreadLowerBound, StrideMulIterPerThreadMinusOne,
+      string("ThreadUpperBound.") + dimensionName);
+
+    // Generate code for loop with computed bounds and stride
+    // CountBoundsBB BasicBlock is a preheader of that loop
+    BasicBlock *AfterBB;
+    Value *IV = createLoopForCUDA(&Builder, lowerBound, upperBound,
+      ThreadLowerBound, ThreadUpperBound, ThreadStride, dimensionName, P, &AfterBB);
+
+    ClastVars[f->iterator] = IV;
+    if (f->body) codegen(f->body);
+
+    // Loop is finished, so remove its iv from the live symbols.
+    ClastVars.erase(f->iterator);
+    AfterBB->moveAfter(Builder.GetInsertBlock());
+
+    // Make block for truncation of threadUpperBound.
+    BasicBlock *truncateThreadUB = SplitBlock(CountBoundsBB, CountBoundsBB->getTerminator(), P);
+    truncateThreadUB->setName(string("CUDA.truncateThreadUB.") + dimensionName);
+    Builder.SetInsertPoint(truncateThreadUB->getTerminator());
+
+    // if(threadUpperBound > loopUpperBound) threadUpperBound = loopUpperBound;
+    Value *isThreadUBgtLoopUB = Builder.CreateICmpSGT(
+      ThreadUpperBound, upperBound, string("isThreadUBgtLoopUB.") + dimensionName);
+    ThreadUpperBound = Builder.CreateSelect(
+      isThreadUBgtLoopUB, upperBound, ThreadUpperBound,
+      string("truncatedThreadUB.") + dimensionName);
+
+    // Get terminator of CountBoundsBB.
+    TerminatorInst * terminator = CountBoundsBB->getTerminator();
+    Builder.SetInsertPoint(CountBoundsBB);
+    // if(threadLowerBound > loopUpperBound) then no execute body et all
+    Value *isThreadLBgtLoopUB = Builder.CreateICmpSGT(
+      ThreadLowerBound, upperBound, string("isThreadLBgtLoopUB.") + dimensionName);
+    Builder.CreateCondBr(isThreadLBgtLoopUB, AfterBB, truncateThreadUB);
+
+    // Erase the old terminator.
+    terminator->eraseFromParent();
+
+    Builder.SetInsertPoint(AfterBB->begin());
+  }
+
+  // Returns true if:
+  // = the list does not contain nested loops;
+  // = the list contains only one nested loop and does not contain assignments or
+  //   user_stmt-s outside this nested list.
+  // Also returns the nested loop pointer to nested_for, if it exists; or NULL otherwise.
+  bool isaGoodListOfStatements(const clast_stmt * stmt,
+    const clast_for * &nested_for, bool & user_or_assignment)
+  {
+    if(!stmt) return true;
+    bool good = true;
+
+    if(CLAST_STMT_IS_A(stmt, stmt_user) || CLAST_STMT_IS_A(stmt, stmt_ass)) {
+      if(nested_for) return false; // there is already anoter loop
+      else user_or_assignment = true;
+    }
+
+    if(CLAST_STMT_IS_A(stmt, stmt_guard))
+      good = isaGoodListOfStatements(
+        ((const clast_guard *)stmt)->then, nested_for, user_or_assignment);
+
+    if(CLAST_STMT_IS_A(stmt, stmt_block))
+      good = isaGoodListOfStatements(
+        ((const clast_block *)stmt)->body, nested_for, user_or_assignment);
+
+    if(CLAST_STMT_IS_A(stmt, stmt_for)) {
+      if(nested_for || user_or_assignment)
+        return false; // there is already a loop or a user_stmt or an assignment
+      else
+        nested_for = (const clast_for *)stmt; // found a loop
+    }
+
+    return good && isaGoodListOfStatements( stmt->next, nested_for, user_or_assignment);
+  }
+
+  int GoodNestedParallelLoops(const clast_stmt * stmt)
+  {
+    int goodLoops = 0;
+    while(goodLoops < 3) {
+      const clast_for * nested_for = NULL;
+      bool user_or_assignment = false;
+      if(isaGoodListOfStatements(stmt, nested_for, user_or_assignment)) {
+        if(nested_for) // if there is a loop
+          if(isParallelFor(nested_for)) { // and it is parallel
+            goodLoops++; // then increment the good loops counter
+            stmt = nested_for->body; // and check the body of this loop
+          } else break; // if there is a non-parallel loop
+        else break; // if no more loops
+      } else break;
+    }
+
+    return goodLoops;
+  }
+
   /// @brief Check if a loop is parallel
   ///
   /// Detect if a clast_for loop can be executed in parallel.
@@ -610,7 +911,7 @@
 
 void ClastStmtCodeGen::codegen(const clast_for *f) {
   bool Vector = PollyVectorizerChoice != VECTORIZER_NONE;
-  if ((Vector || OpenMP) && isParallelFor(f)) {
+  if ((Vector || OpenMP || CUDA) && isParallelFor(f)) {
     if (Vector && isInnermostLoop(f) && (-1 != getNumberOfIterations(f))
         && (getNumberOfIterations(f) <= 16)) {
       codegenForVector(f);
@@ -624,6 +925,12 @@
       parallelCodeGeneration = false;
       return;
     }
+
+    if (CUDA && (int)parallelLoops.size() < goodNestedParallelLoopsCount) {
+      parallelLoops.push_back(f->iterator);
+      codegenForCUDA(f);
+	  return;
+    }
   }
 
   codegenForSequential(f);
@@ -723,6 +1029,11 @@
   parallelCodeGeneration = false;
 
   const clast_stmt *stmt = (const clast_stmt*) r;
+  
+  if(CUDA && ((goodNestedParallelLoopsCount =
+    GoodNestedParallelLoops(stmt->next)) > 0) )
+    createCUDAGridParamsAndPosInGridBlocks();
+
   if (stmt->next)
     codegen(stmt->next);
 }
@@ -744,6 +1055,50 @@
 
   CodeGeneration() : ScopPass(ID) {}
 
+  // Adding prototypes required if OpenMP is enabled.                    
+  // For each dimension defines four functions, which returns parameters 
+  //  threadId                                                           
+  //      blockId                                                            
+  //      BlockDim                                                           
+  //      gridDim                                                            
+  // for a dimension                                                     
+  void addCUDADeclarations(Module *M) {
+    IRBuilder<> Builder(M->getContext());
+    LLVMContext &Context = Builder.getContext();
+    IntegerType *intType = Type::getInt32Ty(Context);
+
+    if (!M->getFunction("llvm.nvvm.read.ptx.sreg.tid.x")) {
+      //  Define all dimensions, that can be used while code generation.
+      dimensions.push_back("x");
+      dimensions.push_back("y");
+      dimensions.push_back("z");
+
+      // Define parameters of dimensions.
+      vector<string> parameters;
+      parameters.push_back("tid");
+      parameters.push_back("ctaid");
+      parameters.push_back("ntid");
+      parameters.push_back("nctaid");
+
+      string prefix1("llvm.nvvm.read.ptx.sreg.");
+      string prefix2(".");
+      string prefix3(".");
+
+      for(unsigned int i = 0; i < dimensions.size(); i++)
+        for(unsigned int j =0; j < parameters.size(); j++) {
+          CudaFunctions.push_back((new string(prefix1 + parameters[j] + 
+            prefix2 + dimensions[i]))->c_str());
+          CudaInricics[CudaFunctions.back()] = (new string(parameters[j] +
+            prefix3 + dimensions[i]))->c_str();
+        }
+
+        for(unsigned int i = 0; i < CudaFunctions.size(); i++) {
+          FunctionType *FT = FunctionType::get(intType, std::vector<Type*>(), false);
+          Function::Create(FT, Function::ExternalLinkage,(CudaFunctions)[i], M);
+        }
+    }
+  }
+
   // Split the entry edge of the region and generate a new basic block on this
   // edge. This function also updates ScopInfo and RegionInfo.
   //
@@ -838,6 +1193,9 @@
 
     assert(region->isSimple() && "Only simple regions are supported");
 
+    Module *M = region->getEntry()->getParent()->getParent();
+    if (CUDA) addCUDADeclarations(M);
+
     // In the CFG the optimized code of the SCoP is generated next to the
     // original code. Both the new and the original version of the code remain
     // in the CFG. A branch statement decides which version is executed.
@@ -882,7 +1240,8 @@
     parallelLoops.insert(parallelLoops.begin(),
                          CodeGen.getParallelLoops().begin(),
                          CodeGen.getParallelLoops().end());
-
+    assert(!verifyFunction(*(region->getEntry()->getParent())) && 
+	                       "code generation failed : function was broken");
     return true;
   }
 
--- a/llvm/tools/polly/lib/Makefile	(revision 156703)
+++ b/llvm/tools/polly/lib/Makefile	(working copy)
@@ -5,7 +5,7 @@
 #
 LEVEL :=..
 
-LIBRARYNAME=LLVMPolly
+LIBRARYNAME=libLLVMPolly
 LOADABLE_MODULE = 1
 
 include $(LEVEL)/Makefile.config
--- a/llvm/tools/polly/include/polly/ScopInfo.h	(revision 181135)
+++ a/llvm/tools/polly/include/polly/ScopInfo.h	(working copy)
@@ -92,9 +92,15 @@
     MayWrite
   };
 
+  enum RelationType {
+    RelationType_general = 0,
+    RelationType_polly = 1
+  };
+
 private:
   isl_map *AccessRelation;
   enum AccessType Type;
+  unsigned elemTypeSize;
 
   const Value *BaseAddr;
   std::string BaseName;
@@ -107,6 +113,10 @@
   /// Updated access relation read from JSCOP file.
   isl_map *newAccessRelation;
 
+  RelationType currentRelationType;
+  isl_map *generalAccessRelation;
+  isl_map *pollyAccessRelation;
+
 public:
   // @brief Create a memory access from an access in LLVM-IR.
   //
@@ -132,6 +142,14 @@
 
   isl_map *getAccessRelation() const;
 
+  void setCurrentRelationType(RelationType relationType);
+
+  RelationType getCurrentRelationType();
+
+  void setGeneralAccessRelation(isl_map *accessRelation);
+
+  void setPollyAccessRelation(isl_map *accessRelation);
+
   /// @brief Get an isl string representing this access function.
   std::string getAccessRelationStr() const;
 
@@ -139,6 +157,8 @@
 
   const std::string &getBaseName() const { return BaseName; }
 
+  unsigned getElemTypeSize() const { return elemTypeSize; }
+
   const Instruction *getAccessInstruction() const { return Inst; }
 
   /// @brief Get the new access function imported from JSCOP file
